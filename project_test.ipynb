{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sqlalchemy clickhouse-connect python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dotenv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mload_dotenv\u001b[49m(override\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_dotenv' is not defined"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to connect to the PostgreSQL database.\n",
      "(psycopg2.OperationalError) connection to server on socket \"@localhost/.s.PGSQL.5432\" failed: Invalid argument (0x00002726/10022)\n",
      "\tIs the server running locally and accepting connections on that socket?\n",
      "\n",
      "(Background on this error at: https://sqlalche.me/e/14/e3q8)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "def get_postgres_engine():\n",
    "    try:\n",
    "        engine = create_engine(\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{dbname}\".format(\n",
    "                                user=os.getenv('pg_user'),\n",
    "                                password=os.getenv('pg_password'),\n",
    "                                host=os.getenv('pg_host'), \n",
    "                                port=os.getenv('pg_port'), \n",
    "                                dbname=os.getenv('pg_dbname')\n",
    "                                )\n",
    "                              )\n",
    "        with engine.connect() as connection:\n",
    "            print(\"Connection to the PostgreSQL database was successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error: Unable to connect to the PostgreSQL database.\")\n",
    "        print(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_postgres_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "# Define the function to get the Snowflake connection\n",
    "def get_snowflake_connection():\n",
    "    connection_string = (\n",
    "        \"snowflake://{user}:{password}@{account}/{database}/{schema}\"\n",
    "        \"?warehouse={warehouse}&role={role}\"\n",
    "    )\n",
    "    connection_url = connection_string.format(\n",
    "        user=os.getenv('sn_user'),\n",
    "        password=os.getenv('sn_password'),\n",
    "        account=os.getenv('sn_account_identifier'),\n",
    "        database=os.getenv('sn_database'),\n",
    "        schema=os.getenv('sn_schema'),\n",
    "        warehouse=os.getenv('sn_warehouse'),\n",
    "        role=os.getenv('sn_role')\n",
    "    )\n",
    "    engine = create_engine(connection_url)\n",
    "    return engine\n",
    "\n",
    "# Define a function to test the connection\n",
    "def test_snowflake_connection(engine):\n",
    "    try:\n",
    "        # Create a connection\n",
    "        connection = engine.connect()\n",
    "        # Run a simple query\n",
    "        query = \"SELECT current_timestamp()\"\n",
    "        result = connection.execute(query)\n",
    "        # Fetch the result\n",
    "        current_timestamp = result.fetchone()\n",
    "        print(\"Connection successful! Current timestamp:\", current_timestamp)\n",
    "        connection.close()\n",
    "    except Exception as e:\n",
    "        print(\"Connection failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful! Current timestamp: (datetime.datetime(2024, 7, 7, 16, 5, 25, 937000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>),)\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "import os\n",
    "\n",
    "def get_snowflake_connection():\n",
    "    conn = snowflake.connector.connect(\n",
    "        user=os.getenv('sn_user'),\n",
    "        password=os.getenv('sn_password'),\n",
    "        account=os.getenv('sn_account_identifier'),\n",
    "        warehouse=os.getenv('sn_warehouse'),\n",
    "        database=os.getenv('sn_database'),\n",
    "        schema=os.getenv('sn_schema'),\n",
    "        role=os.getenv('sn_role')\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "def test_snowflake_connection():\n",
    "    try:\n",
    "        conn = get_snowflake_connection()\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"SELECT current_timestamp()\")\n",
    "        result = cur.fetchone()\n",
    "        print(\"Connection successful! Current timestamp:\", result)\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(\"Connection failed:\", e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_snowflake_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake. Current date in Snowflake: 2024-07-07\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import os\n",
    "from snowflake.sqlalchemy import URL\n",
    "\n",
    "def test_snowflake_connection():\n",
    "    try:       \n",
    "        # Create Snowflake URL\n",
    "        snowflake_url = URL(\n",
    "            user=os.getenv('sn_user'),\n",
    "            password=os.getenv('sn_password'),\n",
    "            account=os.getenv('sn_account_identifier'),\n",
    "            database=os.getenv('sn_database'),\n",
    "            schema=os.getenv('sn_schema'),\n",
    "            warehouse=os.getenv('sn_warehouse'),\n",
    "            role=os.getenv('sn_role')\n",
    "        )\n",
    "\n",
    "        # Create SQLAlchemy engine\n",
    "        engine = create_engine(snowflake_url)\n",
    "\n",
    "        # Test the connection by executing a simple query\n",
    "        with engine.connect() as connection:\n",
    "            result = connection.execute(\"SELECT CURRENT_DATE()\").fetchone()\n",
    "            print(f\"Connected to Snowflake. Current date in Snowflake: {result[0]}\")\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Error connecting to Snowflake: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_snowflake_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading CSV data to Snowflake: 'Engine' object has no attribute 'cursor'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\villy\\AppData\\Local\\Temp\\ipykernel_35792\\567958940.py:42: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df.to_sql(table_name, con=engine, schema=schema, if_exists='append', index=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from snowflake.sqlalchemy import URL\n",
    "\n",
    "def create_snowflake_engine():\n",
    "    try:\n",
    "        # Retrieve Snowflake connection parameters from environment variables\n",
    "        snowflake_user = os.getenv('sn_user')\n",
    "        snowflake_password = os.getenv('sn_password')\n",
    "        snowflake_account = os.getenv('sn_account_identifier')\n",
    "        snowflake_warehouse = os.getenv('sn_warehouse')\n",
    "        snowflake_database = os.getenv('sn_database')\n",
    "        snowflake_schema = os.getenv('sn_schema')\n",
    "        snowflake_role = os.getenv('sn_role')\n",
    "\n",
    "        # Create Snowflake URL\n",
    "        snowflake_url = URL(\n",
    "            user=snowflake_user,\n",
    "            password=snowflake_password,\n",
    "            account=snowflake_account,\n",
    "            database=snowflake_database,\n",
    "            schema=snowflake_schema,\n",
    "            warehouse=snowflake_warehouse,\n",
    "            role=snowflake_role\n",
    "        )\n",
    "\n",
    "        # Create SQLAlchemy engine and return it\n",
    "        engine = create_engine(snowflake_url)\n",
    "        return engine\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating Snowflake engine: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_csv_to_snowflake(engine, schema, table_name, csv_file_path):\n",
    "    try:\n",
    "        # Load CSV into Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Write DataFrame to Snowflake table using SQLAlchemy Engine\n",
    "        df.to_sql(table_name, con=engine, schema=schema, if_exists='append', index=False)\n",
    "\n",
    "        print(f\"Successfully loaded CSV data into Snowflake table '{schema}.{table_name}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV data to Snowflake: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    snowflake_engine = create_snowflake_engine()\n",
    "\n",
    "    if snowflake_engine:\n",
    "        schema = 'STG'\n",
    "        table_name = 'tripsdata'\n",
    "        csv_file_path = './raw_data/tripsdata.csv'\n",
    "\n",
    "        load_csv_to_snowflake(snowflake_engine, schema, table_name, csv_file_path)\n",
    "    else:\n",
    "        print(\"Failed to create Snowflake engine.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from snowflake.sqlalchemy import URL\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_snowflake_engine():\n",
    "    try:\n",
    "        # Retrieve Snowflake connection parameters from environment variables\n",
    "        snowflake_user = os.getenv('sn_user')\n",
    "        snowflake_password = os.getenv('sn_password')\n",
    "        snowflake_account = os.getenv('sn_account_identifier')\n",
    "        snowflake_warehouse = os.getenv('sn_warehouse')\n",
    "        snowflake_database = os.getenv('sn_database')\n",
    "        snowflake_schema = os.getenv('sn_schema')\n",
    "        snowflake_role = os.getenv('sn_role')\n",
    "\n",
    "        # Create Snowflake URL\n",
    "        snowflake_url = URL(\n",
    "            user=snowflake_user,\n",
    "            password=snowflake_password,\n",
    "            account=snowflake_account,\n",
    "            database=snowflake_database,\n",
    "            schema=snowflake_schema,\n",
    "            warehouse=snowflake_warehouse,\n",
    "            role=snowflake_role\n",
    "        )\n",
    "\n",
    "        # Create SQLAlchemy engine and return it\n",
    "        engine = create_engine(snowflake_url)\n",
    "        return engine\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating Snowflake engine: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_csv_to_snowflake(engine, schema, table_name, csv_file_path):\n",
    "    try:\n",
    "        # Load CSV into Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Write DataFrame to Snowflake table using SQLAlchemy Engine\n",
    "        df.to_sql(table_name, con=engine, schema=schema, if_exists='append', index=False)\n",
    "\n",
    "        print(f\"Successfully loaded CSV data into Snowflake table '{schema}.{table_name}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV data to Snowflake: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    snowflake_engine = create_snowflake_engine()\n",
    "\n",
    "    if snowflake_engine:\n",
    "        schema = 'STG'\n",
    "        table_name = 'tripsdata'\n",
    "        csv_file_path = './raw_data/tripsdata.csv'\n",
    "\n",
    "        load_csv_to_snowflake(snowflake_engine, schema, table_name, csv_file_path)\n",
    "    else:\n",
    "        print(\"Failed to create Snowflake engine.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from snowflake.sqlalchemy import URL\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "HTTPDriver for https://github.demo.trial.altinity.cloud:8443 returned response code 400)\n Code: 6. DB::Exception: Cannot parse string '2015-05-01 ' as Date: syntax error at position 10 (parsed just '2015-05-01'): In scope SELECT pickup_date, vendor_id, passenger_count, trip_distance, payment_type, fare_amount, tip_amount FROM tripdata WHERE pickup_date = (toDate('2015-05-01 ') + 1). (CANNOT_PARSE_TEXT) (version 24.5.3.5 (official build))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m engine \u001b[38;5;241m=\u001b[39m get_snowflake_engine()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Execute the fetch data with parameters client and query\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mfetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\villy\\Documents\\GitHub\\taxi-trips-etl-orchestration\\extract_clickhouse.py:62\u001b[0m, in \u001b[0;36mfetch_data\u001b[1;34m(client, engine)\u001b[0m\n\u001b[0;32m     55\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124m    select pickup_date, vendor_id, passenger_count, trip_distance, payment_type, fare_amount, tip_amount\u001b[39m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124m    from tripdata\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124m    where pickup_date = toDate(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) + 1\u001b[39m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# execute the query\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m rows \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mresult_rows\n\u001b[0;32m     64\u001b[0m cols \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mcolumn_names\n",
      "File \u001b[1;32mc:\\Users\\villy\\Documents\\GitHub\\taxi-trips-etl-orchestration\\venv\\Lib\\site-packages\\clickhouse_connect\\driver\\client.py:208\u001b[0m, in \u001b[0;36mClient.query\u001b[1;34m(self, query, parameters, settings, query_formats, column_formats, encoding, use_none, column_oriented, use_numpy, max_str_len, context, query_tz, column_tzs, external_data)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mas_query_result()\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult([response] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [[response]])\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_with_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\villy\\Documents\\GitHub\\taxi-trips-etl-orchestration\\venv\\Lib\\site-packages\\clickhouse_connect\\driver\\httpclient.py:219\u001b[0m, in \u001b[0;36mHttpClient._query_with_context\u001b[1;34m(self, context)\u001b[0m\n\u001b[0;32m    217\u001b[0m     fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext/plain; charset=utf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 219\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mserver_wait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstreaming\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m byte_source \u001b[38;5;241m=\u001b[39m RespBuffCls(ResponseSource(response))  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    227\u001b[0m context\u001b[38;5;241m.\u001b[39mset_response_tz(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_tz_change(response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX-ClickHouse-Timezone\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[1;32mc:\\Users\\villy\\Documents\\GitHub\\taxi-trips-etl-orchestration\\venv\\Lib\\site-packages\\clickhouse_connect\\driver\\httpclient.py:448\u001b[0m, in \u001b[0;36mHttpClient._raw_request\u001b[1;34m(self, data, params, headers, method, retries, stream, server_wait, fields, error_handler)\u001b[0m\n\u001b[0;32m    446\u001b[0m     error_handler(response)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_error_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\villy\\Documents\\GitHub\\taxi-trips-etl-orchestration\\venv\\Lib\\site-packages\\clickhouse_connect\\driver\\httpclient.py:371\u001b[0m, in \u001b[0;36mHttpClient._error_handler\u001b[1;34m(self, response, retried)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     err_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe ClickHouse server returned an error.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 371\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OperationalError(err_str) \u001b[38;5;28;01mif\u001b[39;00m retried \u001b[38;5;28;01melse\u001b[39;00m DatabaseError(err_str) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: HTTPDriver for https://github.demo.trial.altinity.cloud:8443 returned response code 400)\n Code: 6. DB::Exception: Cannot parse string '2015-05-01 ' as Date: syntax error at position 10 (parsed just '2015-05-01'): In scope SELECT pickup_date, vendor_id, passenger_count, trip_distance, payment_type, fare_amount, tip_amount FROM tripdata WHERE pickup_date = (toDate('2015-05-01 ') + 1). (CANNOT_PARSE_TEXT) (version 24.5.3.5 (official build))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from db_utils import get_client, get_snowflake_engine\n",
    "from extract_clickhouse import fetch_data\n",
    "\n",
    "client = get_client()\n",
    "engine = get_snowflake_engine()\n",
    "\n",
    "# Execute the fetch data with parameters client and query\n",
    "fetch_data(client=client, engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
